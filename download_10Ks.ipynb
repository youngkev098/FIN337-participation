{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5 Scrapping Data\n",
    "### Kevin Williams "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from requests_html import HTMLSession\n",
    "import os\n",
    "import re\n",
    "from time import sleep\n",
    "from tqdm.notebook import tqdm # progress bar\n",
    "from NEAR_regex import NEAR_regex \n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SECTION 1: get the data that can build the urls)\n",
    "\n",
    "if not os.path.exists('input/2007_inv_and_tech.dta'):\n",
    "\n",
    "    # grab ccm from lehigh DA Github\n",
    "    ccm = pd.read_stata('https://github.com/LeDataSciFi/lectures-spr2020/blob/master/assignment_data/2007_inv_and_tech.dta?raw=true')\n",
    "    # save to my computer    \n",
    "    ccm.to_stata('input/2007_inv_and_tech.dta')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # load from my computer\n",
    "    ccm = pd.read_stata('input/2007_inv_and_tech.dta')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d5f25e505443118c07054a1b9bd982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Crawling in progress', max=338, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### SECTION 2: crawl the urls\n",
    "\n",
    "session = HTMLSession()\n",
    "for row in tqdm(ccm.index, desc='Crawling in progress'): \n",
    "    row = ccm.iloc[row]\n",
    "    \n",
    "    if row['FName'] != '': \n",
    "        url      = 'https://www.sec.gov/Archives/' + row['FName']\n",
    "        # Allows 10-k form derivaitves to be recognized as independent folders\n",
    "        form     = row['Form'].replace('/','').replace('\\\\','')  \n",
    "        # F-strings: [f'] allows you to print embed python expressions inside string literals for formatting\n",
    "        CoName   = row['CoName'].replace('/','')\n",
    "        folder   =  f'edgar_filings/{CoName}/{form}/fyear_{int(row[\"fyear\"])}/'\n",
    "        filename = row['FName'].split('/')[-1] \n",
    "        filepath = folder + filename\n",
    "        \n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        if not os.path.exists(filepath):\n",
    "            try:\n",
    "                r = session.get(url)\n",
    "            except:\n",
    "                print('failure to get url:',url)  #log error \n",
    "            else:   \n",
    "                with open(filepath,'w',encoding='utf8') as f:\n",
    "                    f.write(r.text)\n",
    "                sleep(2)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
