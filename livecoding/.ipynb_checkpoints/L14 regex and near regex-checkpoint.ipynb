{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mar 5, 2020 Lecture \n",
    "'''\n",
    "Notes:\n",
    "-read over NEAR_regex documentation in participation folder \n",
    "    -code, testcases, (see genius in code)\n",
    "-do more practice with regular expressions \n",
    "\n",
    "\n",
    "for A5 clean 10k, use near_regex. \n",
    "\n",
    "photo in phone looks for different focal word around different key words \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no match\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re # load REGEX package \n",
    "# REGEX functions i'll use: search, findall, finditer, group \n",
    "\n",
    "# re.search(pattern,text)\n",
    "re.search(\"c\",\"abcedef\")\n",
    "\n",
    "type(re.search(\"[d-f]\",\"abcedef\"))\n",
    "\n",
    "\n",
    "if re.search(\"[x-z]\", \"abcdef\"):\n",
    "    print(\"found a match\")\n",
    "else:\n",
    "    print(\"no match\")\n",
    "    \n",
    "re.findall(\"[d-f]{2}\",\"abcdef\")\n",
    "#only returns non overlapping \n",
    "len(re.findall(\"[d-f]{2}\",\"abcdef\"))\n",
    "# how many hits there are!\n",
    "# Review RegexOne to understand regular expressions to use for project 5 \n",
    "\n",
    "#ALWAYS SPUT AN \"r\" BEFORE THE PATTERN!\n",
    "\n",
    "re.findall(r\"\\bc\", \"cabccccccccdef\")\n",
    "#look for c right after the boundary b \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\\bc\"\n",
    "#interperets the string a a rwa string rather than having python see the \\ and assume unicode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\w --> \"word\"characters [A-Za-z0-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hey there guy\"\n",
    "#task: get hey and guy \n",
    "re.findall(\"..y\", text)\n",
    "\n",
    "re.findall(r'\\b\\w{3}\\b', text)\n",
    "#boundary is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "Help on function NEAR_regex in module NEAR_regex:\n",
      "\n",
      "NEAR_regex(list_of_words, max_words_between=5, partial=False, cases_matter=False)\n",
      "        Parameters\n",
      "        ----------\n",
      "        list_of_words : list\n",
      "            A list of \"words\", each element is a string\n",
      "            \n",
      "            This program will return a regex that will look for times where word1 \n",
      "            is near word2, or word2 is near word 1.\n",
      "            \n",
      "            It works with multiple words: You can see if words1 is near word2 or\n",
      "            word3. \n",
      "            \n",
      "        max_words_between : int, optional\n",
      "            How many \"words\" are allowed between words in list_of_words. The default\n",
      "            is 5, but you should consider this carefully.\n",
      "            \n",
      "            \"words\" in between are chunks of characters. \"DON don don- don12 2454\" \n",
      "            is 5 words.\n",
      "            \n",
      "            This will not allow matches if the words are separated by a newline \n",
      "            (\"\n",
      "    \") character.\n",
      "            \n",
      "        partial : Boolean, optional\n",
      "            If true, will accept longer words than you give. For example, if one \n",
      "            word in your list is \"how\", it will match to \"howdy\". Be careful in \n",
      "            choosing this based on your problem. Partial makes more sense with \n",
      "            longer words. \n",
      "            The default is True.\n",
      "            \n",
      "        cases_matter: Boolean, optional bt IMPORTANT\n",
      "            If True, will return a regex string that will only catch cases where  \n",
      "            words in the string have the same case as given as input to this \n",
      "            function. For example, if one word here is \"Hi\", then the regex \n",
      "            produced by this function will not catch \"hi\".\n",
      "            \n",
      "            If false, will return a regex string that will only work if all letters\n",
      "            in search string are lowercase.\n",
      "            \n",
      "            The default is True.\n",
      "         \n",
      "            \n",
      "        Warning / Feature\n",
      "        -------\n",
      "        This WILL NOT \n",
      "        \n",
      "            \n",
      "        Unsure about speed\n",
      "        -------\n",
      "        I don't think this is a very \"fast\" function, but it should be robust. \n",
      "      \n",
      "        \n",
      "        Suggested use\n",
      "        -------\n",
      "        a_string_you_have = 'Jack and Jill went up the hill'\n",
      "        \n",
      "        # 1. define words and set up the regex\n",
      "        words = ['jack','hill']                         \n",
      "        rgx = NEAR_regex(words)                       \n",
      "        \n",
      "        # 2. convert the string to lowercase before searching!\n",
      "        a_string_you_have = a_string_you_have.lower()   \n",
      "        \n",
      "        # 3. len+findall+rgx = counts the number of times the word groups are close\n",
      "        count = len(re.findall(rgx,test))              \n",
      "        print(count)                                 \n",
      "    \n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        A string which is a regex that can be used to look for cases where all the \n",
      "        input words are near each other.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from NEAR_regex import NEAR_regex\n",
    "\n",
    "help(NEAR_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with out NEAR_regex, I would have to:\n",
    "\n",
    "find \"word1 < (\\w)+>{0:5} word2\"\n",
    "\n",
    "# find word 1 5 words near word 2 befrore and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_string_you_have = 'Jack and Jill went up the hill'\n",
    "# 1. define words and set up the regex\n",
    "words = ['jack','hill']                         \n",
    "rgx = NEAR_regex(words)   \n",
    "rgx\n",
    "#always lowercase string before you search tru then                            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "a_string_you_have = 'Jack and Jill went up the hill, jack again hill, 1\tBreak-in does not really connect with me because jack again hill dance is not really that big as it once was in jack the late 70s hill early 80s. For the most part, common folk, are not really taking to the ground to participate in this style, but many do acknowledge this style in remembrance of the late 70s early 80â€™s overall impact on hip-hop, fashion, and street art. '\n",
    "\n",
    "words = ['jack','(hill|hills)']                         \n",
    "rgx = NEAR_regex(words,max_words_between=3)   \n",
    "a_string_you_have = a_string_you_have.lower()\n",
    "print(len(re.findall(rgx,a_string_you_have)))\n",
    "#always lowercase string before you search tru then     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesla Practice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1318605/000156459019003165/0001564590-19-003165.txt'\n",
    "edgar_resp = requests.get(url)\n",
    "# save the url\n",
    "# then in the next part of assignment, youll load it again\n",
    "# here - i'm skipping those steps so we can grab one document to look at\n",
    "\n",
    "loaded_file = edgar_resp.content\n",
    "\n",
    "from NEAR_regex import NEAR_regex \n",
    "\n",
    "\n",
    "# try to use NEAR_regex... look for it working and failing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Golden Rules section:Pasrsing \n",
    "\n",
    "Remove html tags, and turn the document into a pure text string.\n",
    "Lower case everything.\n",
    "Delete punctuation.\n",
    "Delete all excess whitespace.\n",
    "Now you can search/parse the text.\n",
    "\n",
    "1.Use html tags to change/remove unneeded sections. If there are tables you don't want to parse or useless header or footer information, toss them out. Sometimes, you can use the hmtl tags to extract just the part of files you want. If so, do it! If not, proceed:\n",
    "2.Remove html tags, and turn the document into a pure text string.\n",
    "3.Lower case everything.\n",
    "4.Delete punctuation.\n",
    "5.Delete all excess whitespace.\n",
    "6.Now you can search/parse the text.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " hey  THERE-hasn't John  \n",
      "\n",
      " hey  there-hasn't john  \n",
      "  hey  there hasn t john  \n",
      "hey there hasn t john\n",
      "1\n",
      "hey\n",
      "2\n",
      "  firm  year  prof_a\n",
      "0    x     2      19\n",
      "1    x     2       7\n",
      "2    x     3      25\n",
      "3    y     1      12\n",
      "4    y     2      22\n"
     ]
    }
   ],
   "source": [
    "from NEAR_regex import NEAR_regex \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "text = '''<p>    \\n\\r\\t      <b> hey</b>  THERE-hasn't John </p> '''\n",
    "\n",
    "# golden rule steps 2-5 (these #s refer to the list on the website which has an extra item)\n",
    "no_tags = BeautifulSoup(text).get_text()   # BS removes the html tags\n",
    "print(no_tags)\n",
    "lower = no_tags.lower() \n",
    "print(lower)\n",
    "no_punc = re.sub(r'\\W',' ',lower)  # remove punctuations (\\w is word chars, \\W is the opposite)\n",
    "print(no_punc)\n",
    "cleaned = re.sub(r'\\s+',' ',no_punc).strip()  # remove excess whitespace (\\s is all whitespace)\n",
    "print(cleaned)\n",
    "print(len(re.findall(NEAR_regex(['hey','john']),   cleaned)))\n",
    "# So those are the golden rule steps in action to clean an HTML string and search it.\n",
    "\n",
    "# For the assignment\n",
    "\n",
    "# download_10ks.ipynb will downloads the 10ks. Then, inside parse_10ks.ipynb,\n",
    "\n",
    "from NEAR_regex import NEAR_regex  # copy this file into the asgn folder\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# load the dataset I gave you\n",
    "# something goes here\n",
    "\n",
    "# set up risk \"dictionaries\"\n",
    "battery_risks = ['lithium','risk']\n",
    "# you should set up 3-5 dictionaries of your own. do not use battery risks on the asgn\n",
    "\n",
    "################################################################\n",
    "# practice: parse ONE 10k\n",
    "# when you get this section right, change it so it loops over the 10k on your computer\n",
    "#\n",
    "# i'm not going to load a 10k here, for illustration i'm just downloading tesla's 10k\n",
    "# but again: you should delete the next 3 lines of code and load a 10k from your \n",
    "# directory using the dataset I gave you\n",
    "################################################################\n",
    "\n",
    "url = 'https://www.sec.gov/Archives/edgar/data/1318605/000156459019003165/0001564590-19-003165.txt'\n",
    "edgar_resp = requests.get(url)\n",
    "loaded_file = edgar_resp.content\n",
    "\n",
    "# clean the 10k before searching\n",
    "lower = BeautifulSoup(loaded_file).get_text().lower()\n",
    "no_punc = re.sub(r'\\W',' ',lower)\n",
    "cleaned = re.sub(r'\\s+',' ',no_punc).strip()\n",
    "\n",
    "### now do your searches\n",
    "\n",
    "# search 1\n",
    "print('hey')\n",
    "rgx = NEAR_regex(battery_risks,max_words_between=100,partial=True)\n",
    "s1_hits = len(re.findall(rgx,cleaned))\n",
    "print(s1_hits)\n",
    "\n",
    "import pandas as pd\n",
    "df100 = pd.DataFrame({'firm': ['x','x','x','y','y'], 'year': [1,2,3,1,2], 'prof_a':[19,7,25,12,22]})\n",
    "df100.loc[0,'year'] = s1_hits\n",
    "print(df100)\n",
    "\n",
    "\n",
    "# todo - you need to store the s1_hits in a dataset you can use later\n",
    "\n",
    "# searches 2-5\n",
    "# similar to search 1, but different\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  firm  year  prof_a\n",
      "0    x     1      19\n",
      "1    x     2       7\n",
      "2    x     3      25\n",
      "3    y     1      12\n",
      "4    y     2      22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm</th>\n",
       "      <th>year</th>\n",
       "      <th>prof_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>1000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  firm  year  prof_a\n",
       "0    x  1000      19\n",
       "1    x     2       7\n",
       "2    x     3      25\n",
       "3    y     1      12\n",
       "4    y     2      22"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df100 = pd.DataFrame({'firm': ['x','x','x','y','y'], 'year': [1,2,3,1,2], 'prof_a':[19,7,25,12,22]})\n",
    "print(df100)\n",
    "df100.loc[0,'year'] = 1000\n",
    "\n",
    "df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
