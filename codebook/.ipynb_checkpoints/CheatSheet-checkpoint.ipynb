{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.6666666666666666\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print (2//3) # floor division ans=0\n",
    "print (2/3) # ans= 0.666\n",
    "print(2**3) # exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# and not, or not\n",
    "a = True \n",
    "b = False \n",
    "print(a and b)\n",
    "print(a or b)\n",
    "print(a and not b)  \n",
    "print(not a or not b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"is\" confirms same objects \n",
    "list1 = [] \n",
    "list2 = [] \n",
    "list3=list1 \n",
    "print(list1 == list2)     \n",
    "print(list1 is list2)    \n",
    "print(list1 is list3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two ways to calling functions \n",
    "1. object.function(arguments)\n",
    "2. function(object, arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warnings  \n",
    "Be careful of equality when float are involved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data structures \n",
    "1. lists define with brackets \"[]\"\n",
    "2. tuples define with parentheses \"()\"\n",
    "3. dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc string \n",
    "'''\n",
    "This is a doc string \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If you want to draw random numbers \"set a seed\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 6, 9, 12, 15, 18]\n",
      "[3, 9, 15]\n",
      "[0, 9, 18]\n"
     ]
    }
   ],
   "source": [
    "mylist = list(range(0,20,3))\n",
    "\n",
    "# print(mylist)\n",
    "print(mylist)\n",
    "print(mylist[1::2])\n",
    "print(mylist[0::3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example of sets \n",
    "A set is an unordered collection of unique elements (meaning only singular occurances).\n",
    "You can use curly braces to define sets BTW --> adjectives = {\"cheap\",\"expensive\",\"inexpensive\",\"economical\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def sequence_overlap_count(seq1,seq2):\n",
    "    seq1_set = set(seq1) \n",
    "    seq2_set = set(seq2)\n",
    "    return len(seq1_set & seq2_set)\n",
    " \n",
    "# work on the exercise prompt here\n",
    "    \n",
    "print(sequence_overlap_count((1,2,3),[1,2,3])) # leave this, it's a test unit ... 3\n",
    "print(sequence_overlap_count('hey there','batter up')) # leave this, it's a test unit ... 4\n",
    "print(sequence_overlap_count('j',['jet','sweep'])) # leave this, it's a test unit. answer should be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membership "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "a=3\n",
    "b=[1,2,3]\n",
    "print(a in b)\n",
    "print(a not in b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# good function documentation \n",
    "Document all methods like this, so that help(function) can return doc string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function f in module __main__:\n",
      "\n",
      "f(x, a=1, b=1)\n",
      "    The first argument you give goes to x, the second to a, the third to b.\n",
      "    If you do no provide a or b, they default to the value 1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def f(x, a=1, b=1):\n",
    "    '''\n",
    "    The first argument you give goes to x, the second to a, the third to b.\n",
    "    If you do no provide a or b, they default to the value 1.\n",
    "    '''\n",
    "    if x < 0:\n",
    "        return \"WHOA THIS IS NEGATIVE\"\n",
    "    return [a + b * x, 2] # you can return any object(s) you want! this is a list, for example\n",
    "\n",
    "help(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 3, 3, 7, 9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)  # seed for reproducibility\n",
    "\n",
    "x1 = np.random.randint(10, size=6)  # One-dimension\n",
    "#--------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Array Slicing x[start:stop:step]\n",
    "    # x[1::2]  # every other element, starting at index 1\n",
    "    # x[::-1]  # all elements, reversed \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps in Data analysis using Python \n",
    "1. Data Exploration \n",
    "    (to get a better picture of the data you have)\n",
    "2. Data Cleaning \n",
    "    (check if there are any impossible values, are there outliers, are there missing or duplicate observations? Essentially check if the data useable)\n",
    "3. Create Summary Sub-Tables \n",
    "        (essentially break the data into a more digestiable format to present to my MD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Functions\n",
    "\n",
    "Lambda Functions are annonymous functions (declared with no name) that \n",
    "can take any number of arguments but contain only a single expressions. \n",
    "Lambdas are used when: \n",
    "1. you need a function for a short period of time \n",
    "2. you want to pass a function as an argument to higher order functions \n",
    "\n",
    "EX.\n",
    "1. product = lambda x,y: x*y\n",
    "print product(2,3) --> 6 \n",
    "\n",
    "2.def testfunc(num:\n",
    "    return lambda x: x* num\n",
    "result1 = testfunc(10)\n",
    "print(result(9)) ---> 90\n",
    "\n",
    "* more advanced --> applying functions to DF \n",
    "df.apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The shape of the data matters for all plotting functions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- merged_data.drop_duplicates(['permno'])\n",
    "    -get rid of duplicates || .drop_duplicates(['column'])\n",
    "- access cell value || .at[index, 'column']\n",
    "    -print(df['column'])  --> column data \n",
    "\n",
    "EX \n",
    "- print(stocks[:5])\n",
    "- print(stocks.at[4, 'ret'])\n",
    "- print(stocks[:4]['ret'].mean())\n",
    "- print columns from a df --> df.columns \n",
    "- ccm['prof_a'].where(ccm['prof_a'] > 197) returns the values in prof_a where column ____(prof_a) > 197\n",
    "- list(codes.columns)  # prints columns \n",
    "\n",
    "df.loc[df['Column'] == 'value']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nisna() | notna()\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "isna() | notna()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formating "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- print(\"M/B max: \",\"{0:.3f}\".format(ccm['mb'].max()))\n",
    "    - this formats max() to have 3 decimal places after the zero \n",
    "- print(\"M/B max: \",round(ccm['mb'].max(),3))\n",
    "    - this is an easier way to get to 3 decimal places \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can reference the previous row using shift \n",
    "'''\n",
    "df['Change'] = df.A - df.A.shift(1)\n",
    "df\n",
    "\n",
    "    A   Change\n",
    "0   100 NaN\n",
    "1   101 1.0\n",
    "2   102 1.0\n",
    "3   103 1.0\n",
    "4   104 1.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a DataFrame and Creating a new column based on subtracting values in another "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm</th>\n",
       "      <th>year</th>\n",
       "      <th>prof_a</th>\n",
       "      <th>prof_a_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>1000</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>-13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  firm  year  prof_a  prof_a_diff\n",
       "0    x  1000      19          NaN\n",
       "1    x     2       7        -12.0\n",
       "2    x     3      25         18.0\n",
       "3    y     1      12        -13.0\n",
       "4    y     2      22         10.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df100 = pd.DataFrame({'firm': ['x','x','x','y','y'], 'year': [1,2,3,1,2], 'prof_a':[19,7,25,12,22]})\n",
    "\n",
    "df100=df100.assign(prof_a_diff=df100.prof_a-df100.prof_a.shift(1))\n",
    "# df100 = df100.groupby(['firm'])['prof_a_diff'].apply(df100.prof_a-df100.prof_a.shift(1))\n",
    "# # df100.prof_a-df100.prof_a.shift(1))\n",
    "df100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replacing column values in a pandas DataFrame\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[<row selection>, <column selection>]\n",
    "# df100.loc[0,'year'] = 1000\n",
    "# df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert sic to str then grab 1st two char then convert back to int\n",
    "    .assign(sic2=temp3.sic.astype(str).str[:2].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check for value in df \n",
    "- df['ticker'].isin(['GS']).any()\n",
    "- checks if GS is in the ENTIRE column ticker and returns a bool \n",
    "- not including.any() would return bool for each index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Comprehension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [expression for item in list if conditional ]\n",
    "#  for item in list:\n",
    "   # if conditional:\n",
    "    #    expression\n",
    "    \n",
    "'''\n",
    "EX.\n",
    "\n",
    "nan_cols = [i for i in ccm.columns if ccm[i].isnull().any()] \n",
    "#find columns with nan and add them to nan_cols \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print selected columns in a df by doing:\n",
    "    \n",
    "    ccm[['lpermno','prof_a','profit_change']]\n",
    "    \n",
    "You can drop columns by doing:\n",
    "\n",
    "    eliminated = my_years.drop(my_years[(my_years.sic2 == 99) (my_years.sic2 == 41)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with .transpose() you can see more variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to identify outliers in data ...\n",
    "\n",
    "1. If you \"standardize\" all variables (subtract the mean and divide by the standard deviation - a common first step in many ML analyses!), you could plot the densities on a handful of charts or a tall ridgeline. \n",
    "\n",
    "2. table, but print out percentiles that focus on the tails and look for large jumps near the edges (like from p95 to max)\n",
    "\n",
    "#a table approach to support the list of variables above\n",
    "ccm.describe(percentiles[.01,.05,.95,.99]).transpose().style.format('{:.2f}')\n",
    "3. make a table with skewness and kurtosis variables (look for fat and/or long tails)\n",
    "\n",
    "4. boxplots, but you'll need to do a bunch of them | Histograms might be better to spot outliers but would require ~40 figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "             \n",
    "# inds_to_examine == \n",
    "[82.0, 31.0, 63.0, 47.0, 70.0, 27.0, 75.0, 61.0]\n",
    "\n",
    "- in the next line: the @ sign tells python to put the variable inside the string\n",
    "sns.lineplot(data = sic2_year.query('sic2 in @inds_to_examine').reset_index(),\n",
    "             x = 'fyear', y='td_a', hue='sic2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # df.floordiv(#) | .nlargest() |.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A       B        C      D\n",
      "0  500  1100.0   4010.0   5213\n",
      "1  300     NaN  34313.0  43134\n",
      "2  600  4000.0    835.0    253\n",
      "3  400  3000.0      NaN    853\n",
      "\n",
      "    A     B      C    D\n",
      "0  5  11.0   40.0   52\n",
      "1  3  91.0  343.0  431\n",
      "2  6  40.0    8.0    2\n",
      "3  4  30.0   91.0    8\n",
      "\n",
      "      A       B        C      D\n",
      "1  300     NaN  34313.0  43134\n",
      "0  500  1100.0   4010.0   5213\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"A\":[500, 300, 600, 400], \n",
    "                   \"B\":[1100, None, 4000, 3000], \n",
    "                   \"C\":[4010, 34313, 835, None], \n",
    "                   \"D\":[5213, 43134, 253, 853]})\n",
    "\n",
    "print(df)\n",
    "print('\\n',df.floordiv(100, fill_value = (9111)))  # floor divide sic by 100 to form new column sic2\n",
    "print('\\n',df.nlargest(2,'D'))\n",
    "\n",
    "# .reset_index()\n",
    "\n",
    "# .nsmallest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example on .tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['sic2'].to_list() --> turns a series into a list\n",
    "\n",
    "lev_avg2007 = ccmfilt.query('fyear == \"2007\"').groupby(['sic2','fyear'])['td_a'].mean() \n",
    "# filter for 2007 then do avg leverage\n",
    "print(lev_avg2007.nlargest(4)) # what are 4 largest results?\n",
    "# sic2  fyear \n",
    "# 61.0  2007.0    0.506573\n",
    "# 75.0  2007.0    0.476821\n",
    "# 27.0  2007.0    0.456561\n",
    "# 70.0  2007.0    0.456277\n",
    "# Name: td_a, dtype: float3\n",
    "top4 = lev_avg2007.nlargest(4).reset_index()\n",
    "print(top4)\n",
    "#    sic2   fyear      td_a\n",
    "# 0  61.0  2007.0  0.506573\n",
    "# 1  75.0  2007.0  0.476821\n",
    "# 2  27.0  2007.0  0.456561\n",
    "# 3  70.0  2007.0  0.456277\n",
    "\n",
    "top4 = lev_avg2007.nlargest(4).reset_index()['sic2'].to_list()\n",
    "print(top4)\n",
    "# [61.0, 75.0, 27.0, 70.0]\n",
    "\n",
    "# ******* TO COMBINE TO LISTS USE: + "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/03.07-merge-and-join.html\n",
    "\n",
    "How=\n",
    "inner --> keeps only common values in both left and right DF \n",
    "outer --> joins both DF's, matches where possible and puts NaN's \n",
    "everywhere else \n",
    "left/right --> over left/right entries\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of retriving online data and parsing \n",
    "\n",
    "#Import libraries\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Set the URL you want to webscrape from\n",
    "\n",
    "url = 'http://web.mta.info/developers/turnstile.html'\n",
    "\n",
    "#Connect to the URL\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "#Parse HTML and save to BeautifulSoup object¶\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "\n",
    "#To download the whole data set, let's do a for loop through all a tags\n",
    "\n",
    "line_count = 1 #variable to track what line you are on\n",
    "for one_a_tag in soup.findAll('a'):  #'a' tags are for links\n",
    "    if line_count >= 36: #code for text files starts at line 36\n",
    "        link = one_a_tag['href']\n",
    "        download_url = 'http://web.mta.info/developers/'+ link\n",
    "        urllib.request.urlretrieve(download_url,'./'+link[link.find('/turnstile_')+1:]) \n",
    "        time.sleep(1) #pause the code for a sec\n",
    "    #add 1 for next line\n",
    "    \n",
    "    line_count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Golden rules for scraping data \n",
    "\n",
    "# You should check a site's terms and conditions before you scrape them. It's their data and they likely have some rules to govern it.\n",
    "# Be nice - A computer will send web requests much quicker than a user can. Make sure you space out your requests a bit so that you don't hammer the site's server.\n",
    "# Scrapers break - Sites change their layout all the time. If that happens, be prepared to rewrite your code.\n",
    "# Web pages are inconsistent - There's sometimes some manual clean up that has to happen even after you've gotten your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby and Sorting \n",
    "\n",
    "temp99 = sic2_merged.groupby(['sic2','fyear']).apply(lambda x: x.sort_values('avg_lev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1.fig.autofmt_xdate()\n",
    "\n",
    "# plots x _axis horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop, repo setting, ignore files, /pathtofolder*\n",
    "* = ignore any files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word map by looking at two similar firms and highlighting words that are dissimmilar \n",
    "# find the word in the doc and looking at words around it to determine if its a risk \n",
    "\n",
    "\n",
    "\n",
    "# assg5 \n",
    "\n",
    "also highlight how many times that focal word comes up. \n",
    "come up with risk words and have note other words next to it that might signal that its a risk.\n",
    "\n",
    "words that are near it. risk; price; effect, affect, would, could, possibly, increase, decrease, \n",
    "\n",
    "create two dictionaries. one with the focal risks and the second is words around it. you could also \n",
    "determine how \"near\" the word is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   c1   c2\n",
      "0  10  100\n",
      "1  11  110\n",
      "2  12  120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5c2ea463d54b6d8a3e3ba5db48256a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Parsing and searching risks ', max=1, style…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 999\n",
      "1 999\n",
      "2 999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm # progress bar\n",
    "df = pd.DataFrame([{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}])\n",
    "print(df)\n",
    "\n",
    "for index, row in tqdm(df.iterrows(),desc='Parsing and searching risks '):\n",
    "#     row['c1'] = 999\n",
    "    df.at[index,'c1'] = 999\n",
    "    print(index, row['c1'])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.select_dtypes(include=['object']).columns)\n",
    "#selects types within df that are objects. finds the colums and lists them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 5 learned \n",
    "\n",
    "# show all columns\n",
    "# see 6 risk columns added \n",
    "pd.set_option('display.max_columns',None) # view all cols\n",
    "data.head()\n",
    "\n",
    "# From Professor \n",
    ".corr() # lists correlations \n",
    "\n",
    "corr = ccm[['next_rd','next_capx','l_stock_grant_citew','l_stock_trans_in_citew',\n",
    "     'tax_risks’,’proprietary']].corr()\n",
    "\n",
    "Heat Map (to plot correlations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful links\n",
    "- [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/?v=20200122203822)\n",
    "- [Markdown Cheatsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)\n",
    "- [Useful Data Science Online Textbook](https://www.textbook.ds100.org/)\n",
    "\n",
    "### Plots\n",
    "- [Types of graphs](https://python-graph-gallery.com)\n",
    "- [Seaborn plotting tutorial](https://seaborn.pydata.org/tutorial.html)\n",
    "\n",
    "### Getting Data \n",
    "- [Getting Data Walkthrough Example](https://nbviewer.jupyter.org/github/nealcaren/ScrapingData/blob/master/Notebooks/Bonus_Downloading.ipynb)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Putting an Image in a Markdown file !!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://ledatascifi.github.io/lectures-spr2020/04/flowchart.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to print out unique values \n",
    "\n",
    "# fannie_mae['Origination_Date'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
